{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Demo\n",
    "## Practical Implementation of Image Classification with PyTorch using Fashion MNIST Dataset\n",
    "\n",
    "**Run the Computer Vision Demo in a colab notebook**\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/murilogustineli/computer-vision-demo/blob/main/cv_demo.ipynb)\n",
    "\n",
    "**References:**\n",
    "- [TensorFlow tutorial: Basic Image Classification](https://www.tensorflow.org/tutorials/keras/classification?linkId=9317518)\n",
    "- [Fashion MNIST GitHub repo](https://github.com/zalandoresearch/fashion-mnist)\n",
    "- [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition)\n",
    "\n",
    "Welcome to this practical implementation, where we delve into the world of computer vision using PyTorch.\n",
    "\n",
    "Our goal is to develop a practical understanding of Convolutional Neural Networks (CNNs) by implementing a model that can classify different types of clothing. This demo is designed for learners at all levels, so don't worry if some concepts seem new. We'll walk through each step of the process, explaining the key ideas and code details along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check if cuda is available\n",
    "cuda_availability = torch.cuda.is_available()\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Cuda availability: {cuda_availability}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Fashion MNIST dataset\n",
    "\n",
    "In this demo, we use the `Fashion MNIST` dataset, a modern alternative to the classic [MNIST](https://en.wikipedia.org/wiki/MNIST_database) dataset traditionally used for handwriting recognition. \n",
    "\n",
    "Fashion MNIST comprises 70,000 grayscale images, each 28x28 pixels, distributed across 10 different clothing categories. These images are small, detailed, and varied enough to challenge our model while being simple enough for straightforward processing and quick training times.\n",
    "\n",
    "<table>\n",
    "  <tr><td>\n",
    "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
    "         alt=\"Fashion MNIST sprite\"  width=\"600\">\n",
    "  </td></tr>\n",
    "  <tr><td align=\"center\">\n",
    "    <b>Figure 1.</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">Fashion-MNIST samples</a> (by Zalando, MIT License).<br/>&nbsp;\n",
    "  </td></tr>\n",
    "</table>\n",
    "\n",
    "### 1.1 Dataset Structure\n",
    "\n",
    "The dataset is split into two parts:\n",
    "\n",
    "- **Training Set:** This includes `train_images` and `train_labels`. These are the arrays that our model will learn from. The model sees these images and their corresponding labels, adjusting its weights and biases to reduce classification error.\n",
    "\n",
    "- **Test Set:** This comprises `test_images` and `test_labels`. These are used to evaluate how well our model performs on data it has never seen before. This is crucial for understanding the model's generalization capability.\n",
    "\n",
    "### 1.2 Understanding the Data\n",
    "\n",
    "Each image in the dataset is a 28x28 NumPy array. The pixel values range from 0 to 255, with 0 being black, 255 being white, and the various shades of gray in between. The labels are integers from 0 to 9, each representing a specific category of clothing.\n",
    "Class Names\n",
    "\n",
    "The dataset doesn't include the names of the clothing classes, so we will manually define them for clarity when visualizing our results. Here's the mapping:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Label</th>\n",
    "    <th>Class</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0</td>\n",
    "    <td>T-shirt/top</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>Trouser</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>2</td>\n",
    "    <td>Pullover</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>3</td>\n",
    "    <td>Dress</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>4</td>\n",
    "    <td>Coat</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>5</td>\n",
    "    <td>Sandal</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>6</td>\n",
    "    <td>Shirt</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>7</td>\n",
    "    <td>Sneaker</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>8</td>\n",
    "    <td>Bag</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>9</td>\n",
    "    <td>Ankle boot</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "In the following sections, we will load and preprocess this data, design and train a CNN, and finally evaluate its performance on the test set. Let's get started!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining class names\n",
    "class_names = [\n",
    "    'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the dataset\n",
    "\n",
    "Let's load the Fashion MNIST dataset directly from PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Check if running on Google Colab\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    data_dir = '/content/FashionMNIST_data/'\n",
    "else:\n",
    "    data_dir = './FashionMNIST_data/'  # Relative path for local execution\n",
    "\n",
    "# Define transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Seed for reproducibility\n",
    "torch.manual_seed(7)\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST(data_dir, download=True, train=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST(data_dir, download=True, train=False, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining Transformations:**\n",
    "\n",
    "- `transforms.ToTensor()`: Converts the images into PyTorch tensors and scales the pixel values to the range [0, 1].\n",
    "\n",
    "- `transforms.Normalize((0.5,), (0.5,))`: Normalizes the tensor images so that each pixel value is centered around 0 and falls within the range [-1, 1]. This normalization helps in stabilizing the learning process and often leads to faster convergence in deep learning models.\n",
    "\n",
    "### 2.1 Using DataLoader\n",
    "\n",
    "The `DataLoader` in PyTorch provides batches of data, and you can iterate through these batches to collect all images and labels. This method is memory-efficient and is typically used when dealing with large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images_labels(loader):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for batch in loader:\n",
    "        b_images, b_labels = batch\n",
    "        images.append(b_images)\n",
    "        labels.append(b_labels)\n",
    "    return torch.cat(images, dim=0), torch.cat(labels, dim=0)\n",
    "\n",
    "# Extracting train and test images and labels\n",
    "train_images, train_labels = extract_images_labels(trainloader)\n",
    "test_images, test_labels = extract_images_labels(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Notes:**\n",
    "\n",
    "- This method will load the entire dataset into memeory, which is fine for small datasets like the Fashion MNIST, but might not be feasible for significantly larger datasets.\n",
    "\n",
    "- `train_images` and `test_images` will be tensors containing the image data, and `train_labels` and `test_labels` will be tensors containing the corresponding labels.\n",
    "\n",
    "- These tensors can then be used directly for training and evaluation in your models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploring the data\n",
    "\n",
    "Before training our model, it's essential to understand the Fashion MNIST dataset's format and structure. This understanding helps in effectively tailoring our model and preprocessing steps.\n",
    "\n",
    "### 3.1 Understanding the Training Set\n",
    "\n",
    "**Size and Shape of Training Images:** The shape of the train_images tensor provides insight into the number of images and their dimensions.\n",
    "    \n",
    "The shape is represented as (N, C, H, W), where:\n",
    "- N = Number of images\n",
    "- C = Number of color channels per image (For grayscale images, C = 1)\n",
    "- H = Height of each image in pixels\n",
    "- W = Width of each image in pixels\n",
    "\n",
    "In our dataset, each image is a 28 x 28 pixel grayscale image, so the shape will be (60000, 1, 28, 28), indicating 60,000 images with 1 color channel and 28x28 pixel resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.shape  # Output expected: (60000, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Training Labels:** The total number of labels in the training set should match the number of images. Each label corresponds to a category of fashion item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_labels)   # Output expected: 60000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Label Range:** Each label is an integer from 0 to 9, where each number corresponds to a specific category (like T-shirts, trousers, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels        # Output example: tensor([9, 8, 3, ..., 7, 7, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Understanding the Test Set\n",
    "\n",
    "- **Size and Shape of Test Images:** The test set should have a similar structure but with fewer images, typically used for evaluating the model's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images.shape   # Output expected: (10000, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Test Labels:** The test set contains labels corresponding to each image, used to verify the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_labels)    # Output expected: 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing\n",
    "\n",
    "Before training our neural network, it's crucial to preprocess the data. This involves scaling the pixel values of the images to a standard range, which helps the network learn more efficiently.\n",
    "\n",
    "### 4.1 Understanding Pixel Values:\n",
    "\n",
    "- Each image in the Fashion MNIST dataset is represented in grayscale with pixel values ranging from 0 to 255.\n",
    "\n",
    "- We applied Scaling and Normalization methods so that each pixel value is centered around 0 and falls within the range [-1, 1].\n",
    "\n",
    "- This normalization is often used in deep learning models as it centers the data around 0, which can lead to faster convergence during training. It can also help mitigate issues caused by different lighting and contrast in images.\n",
    "\n",
    "- The value `-1` represents black, `1` represents white, and the values in between represent various shades of gray.\n",
    "\n",
    "Let's inspect the first image in the training set displaying these pixel values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting firt image\n",
    "plt.figure()\n",
    "plt.imshow(train_images[0][0], cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_color(value:float) -> str:\n",
    "    \"\"\"Returns 'white' for dark pixels and 'black' for light pixels.\"\"\"\n",
    "    return 'white' if value < 0.5 else 'black'\n",
    "\n",
    "image_numpy = train_images[0][0].squeeze().numpy()\n",
    "label = train_labels[0]\n",
    "\n",
    "# Plotting the image\n",
    "plt.figure(figsize=(14,14))\n",
    "plt.imshow(image_numpy, cmap='gray')\n",
    "plt.title(class_names[label], fontsize=16,)\n",
    "plt.grid(False)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "# Overlaying the pixel values\n",
    "for i in range(image_numpy.shape[0]):\n",
    "    for j in range(image_numpy.shape[1]):\n",
    "        plt.text(j, i, '{:.1f}'.format(image_numpy[i,j]), ha='center', va='center', color=get_text_color(image_numpy[i,j]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Verifying the Data Format:\n",
    "\n",
    "- Before building the model, it's a good practice to visualize the data to ensure it's in the correct format. Displaying the first 25 images from the training set can help us confirm that the data is ready for model training.\n",
    "\n",
    "- Additionally, displaying the class name below each image ensures that the labels correspond correctly to the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i][0], cmap='gray') \n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training\n",
    "\n",
    "In deep learning, especially for tasks like image classification, **Convolutional Neural Networks (CNNs)** are often the architecture of choice. CNNs are designed to automatically and adaptively learn spatial hierarchies of features from input images.\n",
    "\n",
    "<table>\n",
    "  <tr><td>\n",
    "    <img src=\"https://learnopencv.com/wp-content/uploads/2023/10/Convolutional-Neural-Network.png\"\n",
    "         alt=\"CNN Architecture\"  width=\"1000\">\n",
    "  </td></tr>\n",
    "  <tr><td align=\"center\">\n",
    "    <b>Figure 2.</b> <a href=\"https://learnopencv.com/understanding-convolutional-neural-networks-cnn/\">Understanding Convolutional Neural Network (CNN): A Complete Guide</a> (by LearnOpenCV).<br/>&nbsp;\n",
    "  </td></tr>\n",
    "</table>\n",
    "\n",
    "### 5.1 Hierarchical Compositionality in CNNs\n",
    "\n",
    "***Complex features are built from simpler ones.***\n",
    "\n",
    "In Convolutional Neural Networks (CNNs), the concept of hierarchical compositionality plays a pivotal role. This idea is based on how CNNs learn to recognize and interpret images through layers that understand increasingly complex features:\n",
    "\n",
    "- **Low-Level Features:** The initial layers of a CNN focus on simple, low-level features such as edges, colors, and basic textures.\n",
    "\n",
    "- **Mid-Level Features:** As the data progresses through the network, these basic features are combined to form mid-level features, like shapes and specific patterns.\n",
    "\n",
    "- **High-Level Features:** In the deeper layers, these combinations further evolve into high-level features that represent more complex aspects of the image, such as entire objects or significant parts of them.\n",
    "\n",
    "<table>\n",
    "  <tr><td>\n",
    "    <img src=\"./figures/Hierarchical-Compositionality.jpg\"\n",
    "         alt=\"Hierarchical Compositionality\"  width=\"1000\">\n",
    "  </td></tr>\n",
    "  <tr><td align=\"center\">\n",
    "    <b>Figure 3.</b> <a href=\"https://omscs.gatech.edu/cs-7643-deep-learning\">CS 7643: Deep Learning</a> (by Zsolt Kira, Georgia Institute of Technology).<br/>&nbsp;\n",
    "  </td></tr>\n",
    "</table>\n",
    "\n",
    "This hierarchical approach allows CNNs to build a deep understanding of images from simple to complex, making them highly effective for tasks like image classification.\n",
    "\n",
    "#### Extra Resources:\n",
    "- **Paper:** [Visualizing and Understanding Convolutional Networks](https://arxiv.org/pdf/1311.2901.pdf)\n",
    "- **CNN Explainer:** [Learn CNNs in your browser!](https://poloclub.github.io/cnn-explainer/)\n",
    "\n",
    "### 5.2 CNN Architecture\n",
    "\n",
    "Let's construct a CNN suitable for the Fashion MNIST dataset using PyTorch's `torch.nn` module. This CNN will consist of convolutional layers for feature extraction followed by fully connected layers for classification.\n",
    "\n",
    "Here's how we can structure our CNN:\n",
    "\n",
    "<!--\n",
    "### Build the Model\n",
    "\n",
    "Setting up the Layers\n",
    "\n",
    "In deep learning, a model is typically constructed from layers. Layers are the fundamental building blocks that process input data and extract relevant features. In PyTorch, layers are implemented using various classes provided in torch.nn module.\n",
    "\n",
    "Let's construct a simple Convolutional Neural Network (CNN) suitable for the Fashion MNIST dataset. Our network will consist of convolutional layers followed by fully connected layers.\n",
    "\n",
    "1. **Flattening:** The images in the Fashion MNIST dataset are 2D (28x28 pixels), but to feed them into a fully connected layer, we need to flatten them into 1D vectors. This is done by reshaping the tensor.\n",
    "\n",
    "2. **Fully Connected Layers:** After flattening the images, we'll pass the data through fully connected (dense) layers. The first dense layer will have 128 neurons and use ReLU (Rectified Linear Unit) as the activation function. The final dense layer will output the class logits, one for each of the 10 classes in the dataset.\n",
    "\n",
    "Here's the PyTorch code for the model:\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NeuralNetClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetClassifier, self).__init__()\n",
    "        # Define layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),               # Flatten the 2D 28x28 image into a 1D vector of 784 pixels\n",
    "            nn.Linear(28*28, 128),      # First fully connected layer: 784 inputs, 128 outputs\n",
    "            nn.BatchNorm1d(128),        # Batch normalization for the first fully connected layer\n",
    "            nn.ReLU(inplace=True),      # ReLU activation function\n",
    "            nn.Linear(128, 10),         # Second fully connected layer: 128 inputs, 10 outputs (classes)\n",
    "            nn.BatchNorm1d(10),         # Batch normalization for the second fully connected layer\n",
    "            nn.ReLU(inplace=True),      # Final ReLU activation function\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)                  # Forward pass through the sequential container\n",
    "        return x\n",
    "\n",
    "# Create the model instance\n",
    "model = NeuralNetClassifier()\n",
    "\n",
    "#### Comments on the Model:\n",
    "\n",
    "- **Sequential Container:** The `nn.Sequential` container simplifies the model definition by automatically arranging the layers in the order they are passed. It's a convenient way to stack layers and activations.\n",
    "\n",
    "- **Fully Connected Layers (nn.Linear):**\n",
    "    - The first `nn.Linear(28*28, 128)` layer takes the flattened input (784 features) and transforms it into a hidden layer with 128 neurons.\n",
    "    - The second `nn.Linear(128, 10)` layer further transforms these 128 features into 10 outputs, corresponding to the 10 classes in the Fashion MNIST dataset.\n",
    "\n",
    "- **Batch Normalization:** `nn.BatchNorm1d` is used after each fully connected layer. Batch normalization standardizes the inputs to a layer for each mini-batch. This stabilizes the learning process and significantly improves the training of deep networks by reducing internal covariate shift.\n",
    "\n",
    "- **ReLU Activation:** `ReLU(inplace=True)` is used as an activation function. The `inplace=True` parameter is a memory optimization. It allows the modification of input data directly, which can save memory by avoiding allocating of additional space for outputs.\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        # Convolutional layers using Sequential\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            # First convolutional layer\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),   # 32 filters, 3x3 kernel, stride 1, padding 1\n",
    "            nn.ReLU(inplace=True),                                  # ReLU activation\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                  # 2x2 Max pooling with stride 2\n",
    "\n",
    "            # Second convolutional layer\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),  # 64 filters, 3x3 kernel, stride 1, padding 1\n",
    "            nn.ReLU(inplace=True),                                  # ReLU activation\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                  # 2x2 Max pooling with stride 2\n",
    "        )\n",
    "\n",
    "        # Fully connected layers using Sequential\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),                                           # Flatten the output of conv layers\n",
    "            nn.Linear(64 * 7 * 7, 128),                             # Fully connected layer with 128 neurons\n",
    "            nn.ReLU(inplace=True),                                  # ReLU activation\n",
    "            nn.Linear(128, 10)                                      # Output layer with 10 neurons for 10 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)                                     # Pass through conv layers\n",
    "        x = self.fc_layers(x)                                       # Pass through fully connected layers\n",
    "        return x\n",
    "\n",
    "# Create the model instance\n",
    "model = CNNClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Architecture explanation:\n",
    "\n",
    "- **Convolutional Layers:** The model starts with two sets of convolutional layers, each followed by a ReLU activation and a max pooling layer. The first `Conv2d` layer takes a single-channel (grayscale) image and applies 32 filters. The second `Conv2d` layer increases the depth to 64 filters.\n",
    "\n",
    "- **ReLU Activation:** After each convolutional layer, a ReLU activation function is used. It introduces non-linearity, allowing the model to learn more complex patterns.\n",
    "\n",
    "- **Max Pooling:** Each max pooling layer (`MaxPool2d`) reduces the spatial dimensions of the feature map by half, helping in reducing the computation and controlling overfitting.\n",
    "\n",
    "- **Fully Connected Layers:** The output from the convolutional layers is flattened into a 1D vector and then passed through two fully connected layers. The first linear layer reduces the dimension to 128, and the second linear layer produces the final output corresponding to the 10 classes.\n",
    "\n",
    "This architecture, structured using the `nn.Sequential` container, offers a clear and compact way to define a CNN in PyTorch. The model is now ready to be trained with the Fashion MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Defining the Loss Function and Optimizer\n",
    "\n",
    "Before training, the model requires a few additional settings, including an optimizer and a loss function:\n",
    "\n",
    "1. **Optimizer:** The optimizer is responsible for updating the model parameters based on the computed gradients. It's crucial for the convergence of the training process.\n",
    "\n",
    "2. **Loss Function:** The loss function measures the discrepancy between the model's predictions and the actual labels. During training, we aim to minimize this loss.\n",
    "\n",
    "Here's how you set up these components in PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Set the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation:\n",
    "\n",
    "- **Cross-Entropy Loss:** We use `nn.CrossEntropyLoss` for multi-class classification. This loss function combines nn.LogSoftmax and nn.NLLLoss in one single class. It is suitable for classification tasks with C classes.\n",
    "\n",
    "- **Adam Optimizer:** `optim.Adam` is used as the optimizer. It's a popular choice due to its effectiveness in handling sparse gradients and adapting the learning rate during training.\n",
    "\n",
    "- **Learning Rate (lr):** This is a hyperparameter that controls how much to change the model in response to the estimated error each time the model weights are updated. Here, it's set to 0.001."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training the Model\n",
    "\n",
    "Having defined the model architecture and set up the loss function and optimizer, we now move to one of the most crucial stages in building a machine learning model -- **training**. \n",
    "\n",
    "Training a model in deep learning involves feeding it data, letting it make predictions, and then adjusting the model parameters (weights) based on the error in its predictions. This process is repeated iteratively and is essential for the model to learn from the data.\n",
    "\n",
    "- **Documentation:** [Training with PyTorch](https://pytorch.org/tutorials/beginner/introyt/trainingyt.html)\n",
    "\n",
    "### 6.1 The Training Loop\n",
    "\n",
    "The core of model training in PyTorch is the training loop. During each iteration (or epoch) of the loop, the model makes predictions (a forward pass), calculates the error (loss), and updates its parameters (a backward pass). Here's a basic outline of what this process involves:\n",
    "\n",
    "1. **Forward Pass:** The model processes the input data and makes predictions.\n",
    "\n",
    "2. **Compute Loss:** The discrepancy between the model's predictions and the actual labels is calculated using the loss function.\n",
    "\n",
    "3. **Backward Pass:** Backpropagation is performed to calculate the gradients of the loss with respect to each model parameter.\n",
    "\n",
    "4. **Update Model Parameters:** The optimizer updates the model parameters using the computed gradients.\n",
    "\n",
    "#### Training Function\n",
    "\n",
    "First, we define a function to encapsulate the training logic for one epoch. This function will handle the forward and backward passes, loss computation, and parameter updates:\n",
    "<!-- Here's how you can implement the training loop in PyTorch: -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, trainloader, optimizer, loss_fn):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in trainloader:\n",
    "        optimizer.zero_grad()  # Zero the gradients to ensure they aren't accumulated\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    average_loss = running_loss / len(trainloader)\n",
    "    print(f'Training Loss: {average_loss:.4f}')\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Function\n",
    "\n",
    "Next, we add a function to perform validation after each training epoch. This function will evaluate the model on a separate validation dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, validloader, loss_fn):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    running_vloss = 0.0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for inputs, labels in validloader:\n",
    "            outputs = model(inputs)\n",
    "            vloss = loss_fn(outputs, labels)\n",
    "            running_vloss += vloss.item()\n",
    "\n",
    "    average_vloss = running_vloss / len(validloader)\n",
    "    print(f'Validation Loss: {average_vloss:.4f}')\n",
    "    return average_vloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Validation Loop\n",
    "\n",
    "With these functions in place, we can structure the overall training and validation loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'EPOCH {epoch + 1}/{EPOCHS}')\n",
    "\n",
    "    # Training\n",
    "    avg_loss = train_one_epoch(model, trainloader, optimizer, loss_fn)\n",
    "\n",
    "    # Validation\n",
    "    avg_vloss = validate(model, testloader, loss_fn)\n",
    "\n",
    "    # Check for improvement and save model\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = f'./saved_models/model_{epoch}.pth'\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(f'Model saved to {model_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate Accuracy in PyTorch\n",
    "\n",
    "Unlike TensorFlow's Keras API, which provides high-level functions like `model.fit` and `model.evaluate`, PyTorch requires you to explicitly define the training loop and the evaluation process. This approach gives you more control and flexibility but also requires more code.\n",
    "\n",
    "First, you'll need to write a function to calculate the accuracy. Then, you'll use this function with your test dataset.\n",
    "#### Accuracy Calculation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(model, testloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # Disable gradient computation during inference\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Function to Evaluate Test Accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "test_accuracy = evaluate_accuracy(model, testloader)\n",
    "print(f'\\nTest Accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation of Accuracy in Image Classification\n",
    "\n",
    "Accuracy is a key metric in image classification that quantifies how often a model correctly predicts the label of an image. It's expressed as the percentage of test images correctly classified by the model.\n",
    "\n",
    "Mathematically, accuracy is defined as the ratio of correct predictions to total predictions:\n",
    "$$\n",
    "\\text{Accuracy}=\\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Predictions}}\n",
    "$$\n",
    "\n",
    "Alternatively, using terms from confusion matrix:\n",
    "$$\n",
    "\\text{Accuracy}=\\frac{TP+TN}{TP+TN+FP+FN}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- **TP (True Positives):** Images correctly identified as belonging to a class.\n",
    "- **TN (True Negatives):** Images correctly identified as not belonging to a class.\n",
    "- **FP (False Positives):** Images incorrectly identified as belonging to a class.\n",
    "- **FN (False Negatives):** Images incorrectly identified as not belonging to a class.\n",
    "\n",
    "In multi-class settings, such as the Fashion MNIST dataset with 10 classes, accuracy is typically calculated as the ratio of correct predictions to total predictions. The use of TP, TN, FP, FN becomes more relevant in binary classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Loading a Trained Model\n",
    "\n",
    "After training your model and saving its state, you can load the model for further inference, evaluation, or continued training. To load a saved model, you'll need to:\n",
    "\n",
    "- **Recreate the Model Architecture:** Instantiate a new object of your model class. It's important that this new model has the same architecture as the one you trained.\n",
    "\n",
    "- **Load the Saved State Dictionary:** Use `torch.load()` to load the saved state dictionary, and then load this state into your newly created model using `model.load_state_dict()`.\n",
    "\n",
    "Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Instantiate the model\n",
    "loaded_model = CNNClassifier()\n",
    "\n",
    "# Step 2: Load the saved state dictionary\n",
    "model_path = './saved_models/model_0.pth'  # Replace with your model's filename\n",
    "loaded_model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# Step 3: Switch the model to evaluation mode if you're doing inference\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
